# Sparkify Data Warehouse
ETL Pipeline in AWS Redshift and S3

## Project Summary
In this project, I build an **ETL Pipeline** (Extraction, Transformation, Loading)
of a large data set from a fictitious music streaming service named *Sparkify*.
The ETL process flows from Amazon Web Service's (AWS) 
Simple Storage Service (S3) 
into staging tables in **AWS Redshift** (for data warehouses).
I then query the staged data into an analytics table.

This will help *Sparkify's* analytics team learn insight about its customer base.

## File Descriptions

#### create_tables.py

#### sql_queries.py

#### etl.py

## Run instructions

